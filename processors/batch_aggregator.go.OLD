package processors

import (
	"context"

	"github.com/birdayz/kstreams"
)

// BatchCountAggregator demonstrates batch processing for counting events by key.
// This is significantly faster than processing one-by-one when using batch store operations.
type BatchCountAggregator[K comparable] struct {
	store    kstreams.BatchKeyValueStore[K, int64]
	ctx      kstreams.BatchProcessorContext[K, int64]
	storeName string
}

// NewBatchCountAggregator creates a batch aggregator that counts events by key.
// This demonstrates the performance benefits of batch processing:
// - Batch read from store (1 operation vs N)
// - Batch write to store (1 operation vs N)
// - Batch forward to downstream (1 operation vs N)
func NewBatchCountAggregator[K comparable](storeName string) kstreams.ProcessorBuilder[K, any, K, int64] {
	return func() kstreams.Processor[K, any, K, int64] {
		return &BatchCountAggregator[K]{
			storeName: storeName,
		}
	}
}

// Init initializes the processor with context and store access.
func (p *BatchCountAggregator[K]) Init(ctx kstreams.ProcessorContext[K, int64]) error {
	// Try to use batch context if available
	if batchCtx, ok := ctx.(kstreams.BatchProcessorContext[K, int64]); ok {
		p.ctx = batchCtx
	} else {
		// Fallback: wrap regular context
		// (won't have batch forwarding, but will work)
		p.ctx = &batchContextAdapter[K, int64]{ctx}
	}

	// Get store and check if it supports batching
	store := ctx.GetStore(p.storeName)
	if batchStore, ok := store.(kstreams.BatchKeyValueStore[K, int64]); ok {
		p.store = batchStore
	} else {
		// Fallback: wrap regular store
		// (will use individual get/set, slower but functional)
		if kvStore, ok := store.(*kstreams.KeyValueStore[K, int64]); ok {
			p.store = &batchStoreAdapter[K, int64]{kvStore}
		}
	}

	return nil
}

// ProcessBatch processes multiple records in a batch for optimal performance.
func (p *BatchCountAggregator[K]) ProcessBatch(ctx context.Context, records []kstreams.Record[K, any]) error {
	// Group records by key to count occurrences
	countsByKey := make(map[K]int64)
	for _, rec := range records {
		countsByKey[rec.Key]++
	}

	// Extract unique keys
	keys := make([]K, 0, len(countsByKey))
	for key := range countsByKey {
		keys = append(keys, key)
	}

	// BATCH READ: Get current counts for all keys in one operation
	currentCounts, err := p.store.GetBatch(keys)
	if err != nil {
		return err
	}

	// Build map of current values
	currentMap := make(map[K]int64, len(currentCounts))
	for _, kv := range currentCounts {
		currentMap[kv.Key] = kv.Value
	}

	// Update counts
	updates := make([]kstreams.KV[K, int64], 0, len(countsByKey))
	outputs := make([]kstreams.KV[K, int64], 0, len(countsByKey))

	for key, increment := range countsByKey {
		newCount := currentMap[key] + increment
		updates = append(updates, kstreams.KV[K, int64]{Key: key, Value: newCount})
		outputs = append(outputs, kstreams.KV[K, int64]{Key: key, Value: newCount})
	}

	// BATCH WRITE: Update all counts in one atomic operation
	if err := p.store.SetBatch(updates); err != nil {
		return err
	}

	// BATCH FORWARD: Send all results downstream in one operation
	return p.ctx.ForwardBatch(ctx, outputs)
}

// Process implements fallback for single-record processing.
func (p *BatchCountAggregator[K]) Process(ctx context.Context, k K, v any) error {
	// Convert to batch of size 1
	return p.ProcessBatch(ctx, []kstreams.Record[K, any]{{Key: k, Value: v}})
}

// Close cleans up resources.
func (p *BatchCountAggregator[K]) Close() error {
	return nil
}

// batchContextAdapter wraps a regular ProcessorContext to provide batch operations.
type batchContextAdapter[K, V any] struct {
	kstreams.ProcessorContext[K, V]
}

func (a *batchContextAdapter[K, V]) ForwardBatch(ctx context.Context, records []kstreams.KV[K, V]) error {
	// Fallback: forward one-by-one
	for _, kv := range records {
		a.Forward(ctx, kv.Key, kv.Value)
	}
	return nil
}

func (a *batchContextAdapter[K, V]) ForwardBatchTo(ctx context.Context, records []kstreams.KV[K, V], childName string) error {
	// Fallback: forward one-by-one
	for _, kv := range records {
		a.ForwardTo(ctx, kv.Key, kv.Value, childName)
	}
	return nil
}

// batchStoreAdapter wraps a regular KeyValueStore to provide batch operations.
type batchStoreAdapter[K comparable, V any] struct {
	*kstreams.KeyValueStore[K, V]
}

func (a *batchStoreAdapter[K, V]) SetBatch(kvs []kstreams.KV[K, V]) error {
	// Fallback: set one-by-one
	for _, kv := range kvs {
		if err := a.Set(kv.Key, kv.Value); err != nil {
			return err
		}
	}
	return nil
}

func (a *batchStoreAdapter[K, V]) GetBatch(keys []K) ([]kstreams.KV[K, V], error) {
	// Fallback: get one-by-one
	results := make([]kstreams.KV[K, V], 0, len(keys))
	for _, k := range keys {
		v, err := a.Get(k)
		if err == kstreams.ErrKeyNotFound {
			continue // Skip missing keys
		}
		if err != nil {
			return nil, err
		}
		results = append(results, kstreams.KV[K, V]{Key: k, Value: v})
	}
	return results, nil
}

func (a *batchStoreAdapter[K, V]) DeleteBatch(keys []K) error {
	// Fallback: delete one-by-one
	for _, k := range keys {
		if err := a.Delete(k); err != nil {
			return err
		}
	}
	return nil
}
